{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Networks\n",
    "For all of the classification problems we have dealt with so far, we have had the luxury of having a **large** amount of training data.  Large data samples tend to be necessary in order to achieve high classification accuracy.\n",
    "\n",
    "But what if our training sample sizes are limited, and yet we still need to achieve high classifier accuracy?  One possibility is to use **data augmentation** - essentially using your training data to **create** more semi-independent training samples.   For image classification, Keras comes with a variety of tools for just that circumstance.\n",
    "\n",
    "However, there are other circumstances where this approach is not practical.  For example, consider the case of the iPhoneX Facial Recognition algorithm.  If we were to approach this as a standard classification algorithm, we could do the following:\n",
    "1.   Get a large number of images containing background faces.\n",
    "2.   Get a large number of images of the iPhone user as our signal.\n",
    "3.   Train the network.\n",
    "The obvious problem with this is steps 2 and 3: getting a large enough sample of signal images as well as training the network (which presumably would have to be done offline and not on the iPhone).  In this case, each user would need a personally trained algorithm.  This approach clar **does not scale**.\n",
    "\n",
    "There is a different approach utilizing **Siamese Networks** which this workbook describes.  To see how this works, let's introduce another data set, called the **Omniglot** dataset.\n",
    "\n",
    "Much of the discussion in this workbook is motivated by the work from this [article](https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d) as well as this [paper](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Omniglot Dataset\n",
    "This is a collection which is superfically similar to the MNIST dataset.   In the MNIST dataset:\n",
    "*  We had a collection of 10 hand drawn digits from 0 through 9.\n",
    "*  Each digit in the training set had approximately 6000 hand drawn examples, each drawn by a different person.   The testing set had about 1000 of each digit.\n",
    "*  The images were in gray scale (1 channel) with a pixel resolution of 28x28.\n",
    "\n",
    "Omniglot is quite different.  From the paper: \"The Omniglot data set was collected by Brenden Lake and his collaborators at MIT via Amazonâ€™s Mechanical Turk to\n",
    "produce a standard benchmark for learning from few examples in the handwritten character recognition domain (Lake et al., 2011).1 Omniglot contains examples from 50 alphabets ranging from well-established international languages like Latin and Korean to lesser known local dialects. It also includes some fictitious character sets such as Aurek-Besh and Klingon.\"\n",
    "\n",
    "For the Omniglot dataset:\n",
    "*  We have a collection of 1623 hand drawn characters from 50 different alphabets. \n",
    "*  Each character has just 20 examples, each drawn by a different person.   There is no formal *test* set.   For our studies, we will arbitrarily split the data into 964 training characters  (20 of each) and 659 validation characters  (20 of each).\n",
    "*  Each image is a gray scale image of resolution 105x105.\n",
    "\n",
    "Lets read this dataset in, and explore it a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "X_train,lang_train = pickle.load(open(\"/fs/scratch/PAS1495/physics6820/siamese/data/train.pickle\",\"rb\"))\n",
    "X_val,lang_val = pickle.load(open(\"/fs/scratch/PAS1495/physics6820/siamese/data/val.pickle\",\"rb\"))\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "#\n",
    "# Create lookup tables which take us from character index to language\n",
    "train_lang_lookup = {}\n",
    "for lang in lang_train:\n",
    "    val_min,val_max = lang_train[lang]\n",
    "    for val in range(val_min,val_max+1):\n",
    "        train_lang_lookup[val] = lang#\n",
    "# Create lookup tables which take us from character index to language\n",
    "val_lang_lookup = {}\n",
    "for lang in lang_val:\n",
    "    val_min,val_max = lang_val[lang]\n",
    "    for val in range(val_min,val_max+1):\n",
    "        val_lang_lookup[val] = lang\n",
    "\n",
    "#\n",
    "print(\"Training shapes:    \",X_train.shape)\n",
    "print(\"Training languages: \",lang_train)\n",
    "#\n",
    "print()\n",
    "print(\"Validation shapes:    \",X_val.shape)\n",
    "print(\"Validation languages:  \",lang_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Characters\n",
    "Lets look at our validation set.   The images are stored in the numpy arrays **X_train** and  **X_val**.   The shape of the validation array is: (659, 20, 105, 105).  \n",
    "*  The first index is tells us which **character** we are viewing, and goes from 0-658.\n",
    "*  The second index tells us which **example of that character** we are viewing, and goes from 0-19.\n",
    "*  The third and fourth indices are the pixel positions of our character. \n",
    "\n",
    "The script below chooses the first 10 characters from 10 different langauages.   Play with the offset and *use_val* to look at different languages and characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "nrows = 10 # how many classes\n",
    "n = 10  # how many examples of each class we will display\n",
    "use_val = val  # switch between validation and training\n",
    "offset = 65  # should not be larger than about 659/10 for val and 964/10 for training\n",
    "if use_val:\n",
    "    if offset*(nrows-1)>X_val.shape[0]:\n",
    "        offset = X_train.shape[0]//nrows\n",
    "else:\n",
    "    if offset*(nrows-1)>X_train.shape[0]:\n",
    "        offset = X_train.shape[0]//nrows\n",
    "\n",
    "for row in range(nrows):\n",
    "    if use_val:\n",
    "        print(\"Validation Language:\",val_lang_lookup[row*offset])\n",
    "    else:\n",
    "        print(\"Training Language:\",train_lang_lookup[row*offset])\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(nrows, n, i + 1 +(row*n))\n",
    "        if use_val:\n",
    "            plt.imshow(X_val[row*offset,i,:,:])\n",
    "        else:\n",
    "            plt.imshow(X_train[row*offset,i,:,:])\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying a Single Character\n",
    "If you keep the defaults above (specifically *val_true=True*) you should see the printout befiore the first line as: \"Validation Language: Gurmukhi\", and the resulting character looks almost like a Latin B with an additional horizontal line through the upper loop.\n",
    "\n",
    "Below we plot a **different** hand drawn version of that same character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "img = X_val[0,15,:,:]\n",
    "print(img.shape)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-way one shot learning\n",
    "Our goal is to associate the above character with the appropriate **character** set it came from (the character - not the alphabet).   We will do this assuming that our network has **not** been trained on this specific character ahead of time.\n",
    "\n",
    "Given the nature of this problem, we will use a different metric to assess our performance:\n",
    "**N-way one shot learning**.   The basic idea is this:\n",
    "*  We randomly select a test character from our dataset.\n",
    "*  We select $N$ other samples to compare our test character to, **one of which** is a **different** version of the **same** test character, while the N-1 other characters are all different characters, each from a different character set.\n",
    "*  We use our model to calculate a **similarity** score, and use this score to choose the best matching character set.  If the chosen character set is the one our test character was drawn from, then our model was correct, otherwise it was wrong.  For each correct case we increment N_correct.\n",
    "*  We do this for many trials N_trials, and our accuracy is then (N_correct/N_trials).\n",
    "\n",
    "A figure showing 9-way one shot learning is shown here (from [this link]):(https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d):\n",
    "![9-way one shot learning](figs/n_way_9.jpeg)\n",
    "\n",
    "\n",
    "A figure showing 16-way one shot learning is shown here (from [this link]):(https://towardsdatascience.com/one-shot-learning-with-siamese-networks-using-keras-17f34e75bb3d):\n",
    "![9-way one shot learning](figs/n_way_16.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model: Guessing\n",
    "If we use the N-way one shot learning method to assess performance, it would be nice to have a simple baseline model to compare against.   The simplest model is guessing:\n",
    "*  For N=2, the expected performance is 1/2 or 50%\n",
    "*  For N=9, the expected performance is 1/9 or 11.1%\n",
    "*  For N=16, the expected performance is 1/16 or 6.25%\n",
    "We should be able to do better than this!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model: Cosine Similarity\n",
    "This is actually a single-nearest-neighbor model, where the distance metric is the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity).  The idea is this:\n",
    "* We think of each of our 105x105 images as 11025(=105x105) dimensional vector.\n",
    "* We calculate the \"cosine\" between each pair of vectors.\n",
    "* The pair with the largest similarity gives us the matching character set.\n",
    "\n",
    "The **nearest_neighbor_cosine** method below implements this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nearest_neighbour_cosine(v1,v2,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    cossim = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        cossim[i] = np.sqrt(np.sum(v1[i]*v2[i])/(np.sum(v1[i]**2)*np.sum(v2[i]**2)))\n",
    "    if np.argmax(cossim) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def nearest_neighbour_L2dist(v1,v2,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt((v1[i]- v2[i])**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-way testing using cosine similarity\n",
    "The code below implements N-way testing for N=5,10,15,20, and compares guessing with the cosine similarity model.  This second model does much better than guessing, but still only achieves about 25% for N=20.  Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "n_classes, n_examples, w, h = X_val.shape\n",
    "letters = list(range(n_classes))\n",
    "examples = list(range(n_examples))\n",
    "#\n",
    "# Loop over different \"N\" values\n",
    "x = []\n",
    "accuracy_nn = []\n",
    "accuracy_guess = []\n",
    "for N in [5,10,15,20]:\n",
    "#\n",
    "# Loop over trials\n",
    "    number_correct = 0\n",
    "    number_trials = 0\n",
    "    for trials in range(5000):\n",
    "#\n",
    "# Each trial shuffle our letters and classes \n",
    "        random.shuffle(letters)\n",
    "        random.shuffle(examples)\n",
    "    #print(examples)\n",
    "#\n",
    "# Get our support indices\n",
    "        support_letters_class_indices = letters[0:N]\n",
    "        support_letters_example_indices = examples[0:N]\n",
    "#\n",
    "# Get the letter to test\n",
    "        test_letter_class_index = letters[0]\n",
    "        test_letter_example_index = examples[0]\n",
    "#\n",
    "# Now get another example (but different) of the test letter\n",
    "        test_letter_class_index_other = letters[0]\n",
    "        test_letter_example_index_other = examples[1]\n",
    "#\n",
    "# The first letter in our support sample is the correct class\n",
    "        support_letters_class_indices[0] = test_letter_class_index_other\n",
    "        support_letters_example_indices[0] = test_letter_example_index_other\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1\n",
    "#\n",
    "# Now form our images\n",
    "        test_images = np.asarray([X_val[test_letter_class_index,test_letter_example_index,:,:]]*N)\n",
    "        test_images = test_images.reshape(N, w, h,1)\n",
    "        support_images = X_val[support_letters_class_indices,support_letters_example_indices,:,:]\n",
    "        support_images = support_images.reshape(N, w, h,1)\n",
    "#\n",
    "# Now get the cosine\n",
    "        res = nearest_neighbour_cosine(test_images,support_images,targets)\n",
    "        number_trials += 1\n",
    "        if res == 1:\n",
    "            number_correct += 1\n",
    "        #print(\"res \",res)\n",
    "    accuracy = round(float(number_correct)/float(number_trials),2)\n",
    "    print(\"N:\",N,\"Number trials:\",number_trials,\"; number correct:\",number_correct,'; accuracy:',accuracy)\n",
    "    x.append(N)\n",
    "    accuracy_nn.append(accuracy)\n",
    "    accuracy_guess.append(1.0/N)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(x, accuracy_nn, 'r--')\n",
    "plt.plot(x, accuracy_guess, 'b-')\n",
    "plt.legend(['Nearest Neighbor', 'Guessing'])\n",
    "plt.xlabel('N-Way')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Networks: Implementation\n",
    "Before we begin, let's recall the basic problem:\n",
    "*  We want a network that can be given a few different images of the same obejct.\n",
    "*  It is then given another image: either of the same object (the signal) or a different object (the background).\n",
    "*  If the new image is simply a different version of our **signal** object, then we want it to output 1, while if it is any other object, we want it to output 0.\n",
    "*  We need to be able to do this **without** retraining the network!\n",
    "\n",
    "The solution to this problem is to train a network to learn the differences between two images, minimizing the loss if the images are very similar, while maximizing the loss if the images are different.  A cartoon of the basic structure is shown below:\n",
    "![siamese network cartoon](figs/siamese_net.jpeg)\n",
    "\n",
    "During training, two images are fed to the network.  The network is a dual-head network, composed of two **identical** CNNs (who share exactly the same weights).   This CNN learns the feature vectors which represent the images.  In our case, the learned feature vector is of size 4096.  The output of these two CNNs are fed into a **Lamba** layer, which in Keras can be used to take the absolute difference between two other Keras layers.   This difference is then fed into a final single outout sigmoid layer.\n",
    "\n",
    "The actual network implemented in the paper is shown here:\n",
    "\n",
    "![siamese network actual](figs/actual_siamese_net_paper.png)\n",
    "This paper is very readable!  You can find it [here](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf).\n",
    "\n",
    "The next code block shows the implementation details for the siamese network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Lambda, Flatten, Dense, Input\n",
    "from keras.initializers import glorot_uniform, RandomNormal\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_siamese_model(input_shape):\n",
    "    \"\"\"\n",
    "        Model architecture based on the one provided in: http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the tensors for the two input images\n",
    "    left_input = Input(input_shape)\n",
    "    right_input = Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (10,10), activation='relu', input_shape=input_shape,\n",
    "                   kernel_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
    "                   kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (7,7), activation='relu',\n",
    "                     kernel_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
    "                     bias_initializer=RandomNormal(mean=0.5, stddev=0.01), \n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(128, (4,4), activation='relu', \n",
    "                     kernel_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
    "                     bias_initializer=RandomNormal(mean=0.5, stddev=0.01), \n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Conv2D(256, (4,4), activation='relu', \n",
    "                     kernel_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
    "                     bias_initializer=RandomNormal(mean=0.5, stddev=0.01), \n",
    "                     kernel_regularizer=l2(2e-4)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='sigmoid',\n",
    "                   kernel_regularizer=l2(1e-3),\n",
    "                   kernel_initializer=RandomNormal(mean=0.0, stddev=0.01),\n",
    "                    bias_initializer=RandomNormal(mean=0.5, stddev=0.01)))\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = Dense(1,activation='sigmoid',bias_initializer=RandomNormal(mean=0.5, stddev=0.01))(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the model\n",
    "The code below makes the model and compiles it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_siamese_model((105, 105, 1))\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Samples for Training\n",
    "This method actually chooses a batch of pairs of training data.   This is a little tricky since true samples need to be **different** examples from the **same** character (or letter), while background samples need to be examples from **different** characters.\n",
    "\n",
    "Half of the pairs are different examples from the same class, while the other half are examples from different classes.  Also, it is importand that we coherently shuffle things at the end of this method, so that during training the network is provided with samples that are randomly from the same set or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "def get_batch(batch_size,use_test_data=False):\n",
    "#\n",
    "# For each batch shuffle\n",
    "    if use_test_data:\n",
    "        n_classes, n_examples, w, h = X_val.shape\n",
    "    else:\n",
    "        n_classes, n_examples, w, h = X_train.shape\n",
    "    letters = list(range(n_classes))\n",
    "    examples = list(range(n_examples))\n",
    "#\n",
    "# Each trial shuffle our letters and classes \n",
    "    random.shuffle(letters)\n",
    "    random.shuffle(examples)\n",
    "    targets = np.zeros((batch_size,))\n",
    "    test_images = np.zeros((batch_size,w, h))\n",
    "    support_images = np.zeros((batch_size,w, h))\n",
    "#\n",
    "# Make sure the batch size is < half the classes\n",
    "    if batch_size < n_classes//2:\n",
    "        half_batch = batch_size//2\n",
    "#\n",
    "# Get the indices for the 1st half - which are pairs from same class\n",
    "        test_letter_class_indices = letters[0:half_batch]\n",
    "        test_letter_example_index = examples[0]\n",
    "        support_letters_class_indices = letters[0:half_batch]\n",
    "        support_letters_example_index = examples[1]\n",
    "#\n",
    "# Are we generating these batches using validation or training data?\n",
    "        if use_test_data:\n",
    "            test_images[0:half_batch,:,:] = X_val[test_letter_class_indices,test_letter_example_index,:,:]\n",
    "            support_images[0:half_batch,:,:] = X_val[support_letters_class_indices,support_letters_example_index,:,:]\n",
    "        else:\n",
    "            test_images[0:half_batch,:,:] = X_train[test_letter_class_indices,test_letter_example_index,:,:]\n",
    "            support_images[0:half_batch,:,:] = X_train[support_letters_class_indices,support_letters_example_index,:,:]\n",
    "        targets[0:half_batch] = 1\n",
    "#\n",
    "# Get the indices for the 2nd half - which are pairs from different classes\n",
    "        test_letter_class_indices = letters[half_batch:batch_size]\n",
    "        test_letter_example_index = examples[0]\n",
    "        support_letters_class_indices = letters[batch_size:batch_size+half_batch]\n",
    "        support_letters_example_index = examples[1]\n",
    "        \n",
    "        if use_test_data:\n",
    "            test_images[half_batch:batch_size,:,:] = X_val[test_letter_class_indices,test_letter_example_index,:,:]\n",
    "            support_images[half_batch:batch_size,:,:] = X_val[support_letters_class_indices,support_letters_example_index,:,:]\n",
    "        else:\n",
    "            test_images[half_batch:batch_size,:,:] = X_train[test_letter_class_indices,test_letter_example_index,:,:]\n",
    "            support_images[half_batch:batch_size,:,:] = X_train[support_letters_class_indices,support_letters_example_index,:,:]\n",
    "        targets[half_batch:batch_size] = 0\n",
    "#\n",
    "# Reshape\n",
    "        test_images = test_images.reshape(batch_size, w, h,1)\n",
    "        support_images = support_images.reshape(batch_size, w, h,1)\n",
    "\n",
    "#\n",
    "# Now shuffle coherently\n",
    "    targets, test_images, support_images = shuffle(targets, test_images, support_images)\n",
    "    pairs = [test_images, support_images]\n",
    "\n",
    "    return pairs, targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating samples for N-way testing\n",
    "This method generates \"N\" pairs of data for N-way testing.   Since this is not data for training, we do not need to shuffle it.   The samples **are** randomly selected, but this is done by shuffling the order of the classes (which are called **letters** below) as well as the order of examples of each letter.  We can then pick these in order. \n",
    "\n",
    "We can pick from the training set (to measure the training performance) or from the validation set (to measure performance on unseen data).\n",
    "\n",
    "Remember that for N-way testing, only 1 of the N pairs contains a matching character pair, whie the other N-1 are pairs contain one character which is the same as the first pair, and one character which is different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_oneshot(N,use_test_data=True):\n",
    "#\n",
    "# For each batch shuffle\n",
    "    if use_test_data:\n",
    "        n_classes, n_examples, w, h = X_val.shape\n",
    "    else:\n",
    "        n_classes, n_examples, w, h = X_train.shape\n",
    "    letters = list(range(n_classes))\n",
    "    examples = list(range(n_examples))\n",
    "#\n",
    "# Each trial shuffle our letters and classes \n",
    "    random.shuffle(letters)\n",
    "    random.shuffle(examples)\n",
    "    #print(examples)\n",
    "#\n",
    "# Get our support indices\n",
    "    support_letters_class_indices = letters[0:N]\n",
    "    support_letters_example_indices = examples[0:N]\n",
    "#\n",
    "# Get the letter to test\n",
    "    test_letter_class_index = letters[0]\n",
    "    test_letter_example_index = examples[0]\n",
    "#\n",
    "# Now get another example (but different) of the test letter\n",
    "    test_letter_class_index_other = letters[0]\n",
    "    test_letter_example_index_other = examples[1]\n",
    "#\n",
    "# The first letter in our support sample is the correct class\n",
    "    support_letters_class_indices[0] = test_letter_class_index_other\n",
    "    support_letters_example_indices[0] = test_letter_example_index_other\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "#\n",
    "# Now form our images\n",
    "    if use_test_data:\n",
    "        test_images = np.asarray([X_val[test_letter_class_index,test_letter_example_index,:,:]]*N)\n",
    "        test_images = test_images.reshape(N, w, h,1)\n",
    "        support_images = X_val[support_letters_class_indices,support_letters_example_indices,:,:]\n",
    "        support_images = support_images.reshape(N, w, h,1)\n",
    "    else:\n",
    "        test_images = np.asarray([X_train[test_letter_class_index,test_letter_example_index,:,:]]*N)\n",
    "        test_images = test_images.reshape(N, w, h,1)\n",
    "        support_images = X_train[support_letters_class_indices,support_letters_example_indices,:,:]\n",
    "        support_images = support_images.reshape(N, w, h,1)\n",
    "        \n",
    "#\n",
    "# Form return\n",
    "    pairs = [test_images, support_images]\n",
    "\n",
    "    return pairs, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Time!\n",
    "Here we actually train our network.  Some explanation:\n",
    "*  **n_iter**: This is *like* the number of **epochs** for training, except in each iteration we choose a random **batch_size** number of samples.\n",
    "*  **evaluate_every**:  This controls how many iterations we will perform before checking the accuracy of the trained network.\n",
    "*  **N_way**: This is the type of N-way testing we will do - the default is 20-way.\n",
    "*  **n_val**: This controls how many training and testing examples we will evaluate to assess performance.\n",
    "\n",
    "Every **evaluate_every** iterations we will check the performance, and if the validation performance has improved, we save both the model and the model parameters.\n",
    "\n",
    "Note:\n",
    "* You can run the network below for a few minutes, but beware: it is very slow.   To train it in the jupyter network will take several hours at least.\n",
    "* There is a python version (assignment17_siamese_prep.py) and an associated **pbs** script (pbs_siam_train_gpu.sh) which you can use to submit this to a GPU node.   **You don't have to do this: I have already trained the model and stored it on the scratch area noted below**.  I have provided these files as examples of a working version should you need access to them in the future.   You can run them if you want though!\n",
    "* For future reference the version submited to a GPU node takes about 15 minutes to train!\n",
    "\n",
    "The saved model is located at: /fs/scratch/PAS1495/physics6820/siamese/models/siam_model.16400.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#\n",
    "# Hyper parameters\n",
    "evaluate_every = 200 # interval for evaluating on one-shot tasks\n",
    "batch_size = 32\n",
    "n_iter = 20000 # No. of training iterations\n",
    "N_way = 20 # how many classes for testing one-shot tasks\n",
    "n_val = 200 # how many one-shot tasks to validate on\n",
    "best = -1\n",
    "#\n",
    "# Now start training\n",
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "#\n",
    "# Get a new batch to test on\n",
    "    (inputs,targets) = get_batch(batch_size)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "#\n",
    "# Every so many iterations, check the training and validation performance\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"i=\",i)\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "#\n",
    "# Now get N-way test results for train and validation sets\n",
    "        n_correct_train = 0\n",
    "        n_correct_val = 0\n",
    "        for testTrials in range(n_val):\n",
    "#\n",
    "# First check training performance\n",
    "            inputs, targets = make_oneshot(N_way,use_test_data=False)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct_train += 1\n",
    "#\n",
    "# Next check validation performace\n",
    "            inputs, targets = make_oneshot(N_way,use_test_data=True)\n",
    "            probs = model.predict(inputs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct_val += 1\n",
    "        train_acc = (100.0 * n_correct_train / n_val)\n",
    "        print(\"     training perf\",train_acc)\n",
    "        val_acc = (100.0 * n_correct_val / n_val)\n",
    "        print(\"   validation perf\",val_acc)\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc\n",
    "            model.save('models/new_siam_model.{}.h5'.format(i))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit task (2 points): How does this relate to the iPhone Face Recognition?\n",
    "The basic idea is this:\n",
    "1.  We have trained a siamese network to give a large loss when the two input images are different, and a small loss when the two input images are from the same class.\n",
    "2.  Now we will use that network.   The validation set can be considered the \"new users\" of our network.   We will ask them to provide 20 \"pictures\" of themselves - at different angles and orientations.  Of course in our case, the 20 \"pictures\" of the same class are simply different versions of the same letter, as drawn by different people.\n",
    "3.  The question we now want to ask:  What is te network output when the two images are from different classes, versus when they are from the same class?\n",
    "\n",
    "To answer this, **make a histogram** of results when the two images come from the same character set (but don't use exactly the same character) and compare (on the same plot) a historgram of the results when the two images come from different character sets.   You can use **get_batch** to do this.\n",
    "\n",
    "Also, if we assume that we will require the output to be above 0.5 for there to be a match, what fraction of signal is found?  What fraction of matches (images with output>0.5) are fake, amming we provide equal numbers of true and fake images as input?\n",
    "\n",
    "Note: The model we use was previously trained as noted above, and can be found:\n",
    "/fs/scratch/PAS1495/physics6820/siamese/models/siam_model.16400.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"/fs/scratch/PAS1495/physics6820/siamese/models/siam_model.16400.h5\")\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra credit task (2 points): What is the N-way performance?\n",
    "Compare on the same plot the N-way performance of the siamese model with the previous guessing and cosine similarity models.   You should just be able to copy the above plot for the guessing/cosine similarity and add another line for the siamese model.  But you have to generate the accuracy numbers for the siamese case.  \n",
    "*  Use N=5,10,15,20.\n",
    "*  Use 500 trials at each N.  \n",
    "*  Use the validation data set!\n",
    "*  Add in the training data set for another point!  Is there any evidence that the network is overtrained?\n",
    "\n",
    "You should be able to make use of **make_oneshot** to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"/fs/scratch/PAS1495/physics6820/siamese/models/siam_model.16400.h5\")\n",
    "\n",
    "accuracy_siamese_train = []\n",
    "accuracy_siamese = []\n",
    "for N in [5,10,15,20]:\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(x, accuracy_siamese_train, 'g-')\n",
    "plt.plot(x, accuracy_siamese, 'g--')\n",
    "plt.plot(x, accuracy_nn, 'r--')\n",
    "plt.plot(x, accuracy_guess, 'b-')\n",
    "plt.legend([\"Siamese Training\",\"Siamese Validation\",'Nearest Neighbor', 'Guessing'])\n",
    "plt.xlabel('N-Way')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda 5.2) [python/3.6-conda5.2]",
   "language": "python",
   "name": "sys_python36conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
