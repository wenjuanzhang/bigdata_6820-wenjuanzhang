{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Analysis for CNN Version\n",
    "As noted in the workbook using the convolutional neural network version of the autoencoder, training takes a **long** time.   So this notebook will be used to analyze the output of the trained AE.   You can use this for both the short version you train in the jupyter notebook, as well as the version you train using straight python.\n",
    "\n",
    "This method of saving data to files - especially for the longer jobs you might run - and then analyzing them in a jupyter notebook, can be helpful for some of the work you might do for your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the models and output pickle file\n",
    "Note that we call the history object we load from pickle \"history_history\", not histroy.history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "short = True\n",
    "if short:\n",
    "    encoder = load_model('fully_trained_encoder_cnn_small.h5')\n",
    "    decoder = load_model('fully_trained_decoder_cnn_small.h5')\n",
    "    autoencoder = load_model('fully_trained_autoencoder_cnn_small.h5')\n",
    "    history_history = pickle.load(open('history_cnn_small.pkl', 'rb')) \n",
    "else:\n",
    "    encoder = load_model('fully_trained_encoder_cnn.h5')\n",
    "    decoder = load_model('fully_trained_decoder_cnn.h5')\n",
    "    autoencoder = load_model('fully_trained_autoencoder_cnn.h5')\n",
    "    history = pickle.load(open('history_cnn.pkl', 'rb')) \n",
    "    history_history = history.history\n",
    "\n",
    "print(\"history\",history_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We will want to run on the data for some of the performance tests, particularly the test data.  Note that we don't load into a pandas datframe the **training** data: pandas dataframes can be **huge** and to save memory we won't load the training data (since we won't do anything woith it in this workbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "#\n",
    "# See this for more info: https://arxiv.org/pdf/1702.05373.pdf\n",
    "mat = sio.loadmat('/fs/scratch/PAS1043/physics6820/emnist/matlab/emnist-byclass.mat')\n",
    "#print(mat)\n",
    "\n",
    "data = mat['dataset']\n",
    "\n",
    "ex_train = data['train'][0,0]['images'][0,0]\n",
    "ey_train = data['train'][0,0]['labels'][0,0]\n",
    "ex_test = data['test'][0,0]['images'][0,0]\n",
    "ey_test = data['test'][0,0]['labels'][0,0]\n",
    "\n",
    "ex_train = ex_train.reshape( (ex_train.shape[0], 28,28), order='F')\n",
    "ex_test = ex_test.reshape( (ex_test.shape[0], 28,28), order='F')\n",
    "\n",
    "ex_train = ex_train.reshape( (ex_train.shape[0], 784))\n",
    "ex_test = ex_test.reshape( (ex_test.shape[0], 784))\n",
    "ex_train = ex_train.astype('float32') / 255.\n",
    "ex_test = ex_test.astype('float32') / 255.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#df_train = pd.DataFrame(ex_train)\n",
    "#df_train['label'] = ey_train\n",
    "#df_digits_train = df_train[df_train['label']<=9]\n",
    "#x_train = df_digits_train.iloc[:50000,:784].values\n",
    "#x_train = x_train.reshape((x_train.shape[0],28,28,1))\n",
    "#y_train = df_digits_train.loc[:50000,'label'].values\n",
    "\n",
    "df_test = pd.DataFrame(ex_test)\n",
    "df_test['label'] = ey_test\n",
    "df_digits_test = df_test[df_test['label']<=9]\n",
    "x_test = df_digits_test.iloc[:,:784].values\n",
    "x_test = x_test.reshape((x_test.shape[0],28,28,1))\n",
    "y_test = df_digits_test['label'].values\n",
    "\n",
    "#\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#y_train_labels_cat = to_categorical(y_train)\n",
    "y_test_labels_cat = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history_history['loss']\n",
    "test_loss = history_history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history_history['mean_squared_error']\n",
    "test_loss = history_history['val_mean_squared_error']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training MSE', 'Test MSE'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance, Part II\n",
    "Next we can try the \"eye test\": do the images at output look close to the images at input?\n",
    "\n",
    "To test this, we first run all of our test images through the **predict** function of our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "print(\"decoded_imgs.shape\",decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the filters of a CNN\n",
    "One thing we have not yet focused on is exactly what our networks are learning.   Clearly the encoder is finding some structure in the digits, and the decoder can then take the structure and recreate at least somewhat the original digits.  \n",
    "\n",
    "If we use the **summary** method of a keras model, we can inspect the structure a bit.  Let's do that for the encoder.\n",
    "\n",
    "When we do this, we will see the output below.  Focusing on just the enocder convolutional layers we see that:\n",
    "1.  The first convolutional layer has 16 filters (the last dimension in the Output Shape column)\n",
    "2.  The second convolutional layer has 8 filters \n",
    "3.  The third convolutional layer has 8 filters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the filters of a CNN (continued)\n",
    "To understand what these filters are doing, we will use a method from Chapter 5 of the Deep Learning with Python text.   The idea is to find an image (starting from a randomly initialized image) which causes each of the filters to respond maximally.   In some sense, this is the stucture that the filter is \"looking for\" in the input images.\n",
    "\n",
    "Here is the relevant code from Chapter 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "#    x *= 0.1\n",
    "    x *= 0.3\n",
    "    \n",
    "    x+= 0.5\n",
    "    x = np.clip(x,0,1)\n",
    "    \n",
    "    x*= 255\n",
    "    x = np.clip(x,0,255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def generate_pattern(model,layer_name,filter_index,size=28):\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:,:,:,filter_index])\n",
    "    grads = K.gradients(loss,model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([model.input],[loss,grads])\n",
    "    input_img_data = np.random.random((1,size,size,1))*20+128.0\n",
    "\n",
    "    step = 1.0\n",
    "    for i in range(40):\n",
    "        loss_value,grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "    \n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(16):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    thisImg = generate_pattern(encoder,'conv2d_1',i)\n",
    "    plt.imshow(thisImg.reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(8):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    thisImg = generate_pattern(encoder,'conv2d_2',i)\n",
    "    plt.imshow(thisImg.reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(8):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    thisImg = generate_pattern(encoder,'conv2d_3',i)\n",
    "    plt.imshow(thisImg.reshape(28,28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda 5.2) [python/3.6-conda5.2]",
   "language": "python",
   "name": "sys_python36conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
